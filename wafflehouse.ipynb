{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def waffles(state):\n",
    "    from BeautifulSoup import BeautifulSoup\n",
    "    import urllib2, sys\n",
    "    import re\n",
    "    import itertools\n",
    "    import pandas as pd\n",
    "    \n",
    "    #first - code to request website info\n",
    "    url  = \"http://www.menuism.com/restaurant-locations/waffle-house-78955/us/\" + state\n",
    "    hdr = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "           'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "           'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "           'Accept-Encoding': 'none',\n",
    "           'Accept-Language': 'en-US,en;q=0.8',\n",
    "           'Connection': 'keep-alive'}\n",
    "\n",
    "    req = urllib2.Request(url, headers=hdr)\n",
    "    page = urllib2.urlopen(req)\n",
    "    content = page.read()\n",
    "    soup = BeautifulSoup(content)\n",
    "    \n",
    "    #second - code to grab all the addresses on the page\n",
    "    rawhtml = soup.findAll(\"ul\", {\"class\":\"\"})\n",
    "\n",
    "    #getting addresses\n",
    "    itemList = []\n",
    "    for item in rawhtml:\n",
    "        itemList.append(''.join(item.findAll(text=True)).split(\"\\n\\n\\n\"))\n",
    "\n",
    "    #flattening the list and removing white space\n",
    "    chain = itertools.chain(*itemList)\n",
    "    chainedList = (list(chain))\n",
    "    addresses = map(lambda x: x.strip(), chainedList)\n",
    "\n",
    "    #getting cities \n",
    "    itemList = []\n",
    "    for item in rawhtml:\n",
    "        itemList.append(item)\n",
    "\n",
    "    #same chaining but this time, i take the raw html tags and flatten them\n",
    "    chain = itertools.chain(*itemList)\n",
    "    chainedList = (list(chain))\n",
    "    y = [item for item in chainedList if len(item) > 1]\n",
    "\n",
    "    #getting final list of cities\n",
    "    cities = []\n",
    "    for i in range(0, len(y)):\n",
    "        cities.append(y[i].a['title'].split('-')[0].split(\" in \")[1])\n",
    "\n",
    "    #creating dataframe from lists\n",
    "    data = pd.DataFrame({'raw': addresses,\n",
    "                         'cities': cities})\n",
    "    data['address'] = map(lambda x: x[x.find(\" at \")+4:len(x)], data['raw'])\n",
    "    data['zip'] = map(lambda x: x[16:21], data['raw'])\n",
    "\n",
    "    #third - get list of all the cities available\n",
    "    allLinks = soup.find(\"ul\", {\"class\":\"list-unstyled-links\"}).findAll(\"a\")\n",
    "\n",
    "    allCities = []\n",
    "    for item in allLinks:\n",
    "        title = item['title']\n",
    "        if title not in allCities:\n",
    "            allCities.append(title)\n",
    "\n",
    "    #clean up list of all cities\n",
    "    newList = map(lambda x: x[16:x.find(\" - \")], allCities)\n",
    "\n",
    "    #find cities that does not have multiple locations because we'll have to pull data from them separately\n",
    "    toRemove = map(lambda x:x.strip(), data['cities'].drop_duplicates().tolist())\n",
    "    remainder = [city for city in newList if city not in toRemove]\n",
    "\n",
    "    #mapping the remainder list and pair it with their respective values to get link\n",
    "    newDict = dict(zip(newList, allCities))\n",
    "\n",
    "    finalDict = {}\n",
    "    for key, value in newDict.iteritems():\n",
    "        if key in remainder:\n",
    "            finalDict[key] = value\n",
    "    \n",
    "    #fourth - scrap addresses from cities with only one restaurant\n",
    "    restaurantList = []\n",
    "    for key, value in finalDict.iteritems():\n",
    "        #load up new url from finalDict values \n",
    "        newUrl = soup.find(\"a\", {\"title\": value})[\"href\"]\n",
    "\n",
    "        #request the new page\n",
    "        req2 = urllib2.Request(newUrl, headers=hdr)\n",
    "        page2 = urllib2.urlopen(req2)\n",
    "        content2 = page2.read()\n",
    "        soup2 = BeautifulSoup(content2)\n",
    "\n",
    "        #parse address from soup2\n",
    "        addyText = str(soup2.find(\"span\",{\"data-listing-attr\":\"address.street\"}).contents)\n",
    "        newAddress = re.sub(r'\\\\n+\\\\t\\\\t\\\\t\\\\t\\\\t\\\\t\\\\t\\\\t', ' ', addyText).split('\\\\t')[1].replace(\"']\",\"\").strip()\n",
    "\n",
    "        #parsing zipcode from soup2\n",
    "        zipText = str(soup2.find(\"span\",{\"data-listing-attr\":\"address.postal_code\"}).contents)\n",
    "        zipCode = re.sub(r'\\\\n+\\\\t\\\\t\\\\t\\\\t\\\\t\\\\t\\\\t\\\\t', ' ', zipText).split('\\\\t')[1].replace(\"']\",\"\").strip()\n",
    "\n",
    "        #create an array of arrays to append to the dataframe\n",
    "        toAdd = [key, \"single loc\", newAddress, zipCode]\n",
    "        restaurantList.append(toAdd)\n",
    "    \n",
    "    #fifth - combine everything together into a dataframe\n",
    "    if len(restaurantList) == 0:\n",
    "        waffles = data\n",
    "        return waffles\n",
    "    else:\n",
    "        final = pd.DataFrame(restaurantList)\n",
    "        final.columns = ['cities', 'raw','address','zip']\n",
    "        waffles = data.append(final)\n",
    "        return(waffles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = waffles('nm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cities</th>\n",
       "      <th>raw</th>\n",
       "      <th>address</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>Waffle House in 87106 at 2250 Yale Blvd Se</td>\n",
       "      <td>2250 Yale Blvd Se</td>\n",
       "      <td>87106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>Waffle House in 87123 at 13207 Central Ave Ne</td>\n",
       "      <td>13207 Central Ave Ne</td>\n",
       "      <td>87123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cities                                            raw  \\\n",
       "0  Albuquerque, NM      Waffle House in 87106 at 2250 Yale Blvd Se   \n",
       "1  Albuquerque, NM   Waffle House in 87123 at 13207 Central Ave Ne   \n",
       "\n",
       "                address    zip  \n",
       "0     2250 Yale Blvd Se  87106  \n",
       "1  13207 Central Ave Ne  87123  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing nm\n",
      "finished with nm\n",
      "processing ny\n",
      "finished with ny\n",
      "processing oh\n",
      "finished with oh\n",
      "processing ok\n",
      "finished with ok\n",
      "processing pa\n",
      "finished with pa\n",
      "processing sc\n",
      "finished with sc\n",
      "processing tn\n",
      "finished with tn\n",
      "processing tx\n",
      "finished with tx\n",
      "processing va\n",
      "finished with va\n",
      "processing wi\n",
      "finished with wi\n",
      "processing wv\n",
      "finished with wv\n"
     ]
    }
   ],
   "source": [
    "listOfStates = ['al','ar','az','ca','co','de','fl','ga',\n",
    "               'il','in','ks','ky','la','md','mi','mo',\n",
    "               'ms','nc','nm','ny','oh','ok','pa','sc',\n",
    "               'tn','tx','va','wi','wv']\n",
    "wafflesdf = pd.DataFrame()\n",
    "for item in listOfStates:\n",
    "    print \"processing \" + item\n",
    "    tempdf = waffles(item)\n",
    "    wafflesdf = wafflesdf.append(tempdf)\n",
    "    print \"finished with \" + item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/home/portfolio/waffles.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-3eb092613859>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwafflesdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/home/portfolio/waffles.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal, **kwds)\u001b[0m\n\u001b[0;32m   1183\u001b[0m                                      \u001b[0mescapechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mescapechar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m                                      decimal=decimal)\n\u001b[1;32m-> 1185\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/format.pyc\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1405\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1406\u001b[0m             f = com._get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m-> 1407\u001b[1;33m                                 encoding=self.encoding)\n\u001b[0m\u001b[0;32m   1408\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/common.pyc\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path, mode, encoding, compression)\u001b[0m\n\u001b[0;32m   2779\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2780\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2781\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2783\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/portfolio/waffles.csv'"
     ]
    }
   ],
   "source": [
    "pd.to_csv('/home/portfolio/waffles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
